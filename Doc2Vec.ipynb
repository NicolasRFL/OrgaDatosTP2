{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Doc2Vec.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvx6IMQ4lyTTpuy9CLFF9B"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"p9bw27bJSrkR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596573985974,"user_tz":180,"elapsed":657,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"4add7953-203d-430d-af14-532440853b8a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"urV_4DfGStK5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596573986390,"user_tz":180,"elapsed":1066,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"b81e5de4-9465-4cf6-e0a9-ea8936d66c11"},"source":["%cd /content/gdrive/My Drive/Kaggle"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Kaggle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7PrGakhJSjBL","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQHabjF-NUQV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1596573995900,"user_tz":180,"elapsed":10559,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"161ce4fb-3a9c-4643-842a-3c3a658f33a4"},"source":["!apt install enchant\n","!pip install pyenchant\n","!pip3 install pyenchant==1.6.6"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","enchant is already the newest version (1.6.0-11.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Requirement already satisfied: pyenchant in /usr/local/lib/python3.6/dist-packages (1.6.6)\n","Requirement already satisfied: pyenchant==1.6.6 in /usr/local/lib/python3.6/dist-packages (1.6.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MH9Lfas_WMPa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1596573995901,"user_tz":180,"elapsed":10554,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"7f4e3dee-e901-4c30-f061-5c705bd254b2"},"source":["import nltk\n","import enchant\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger') \n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import TweetTokenizer\n","import spacy\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from string import punctuation\n","from gensim import models\n","from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n","import re"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yLamwZekSnMI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1596573996347,"user_tz":180,"elapsed":10994,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"d5c59960-9512-4fde-c04b-359e0653ba7d"},"source":["train=pd.read_csv(\"train.csv\",encoding='latin-1')\n","datos =pd.read_csv(\"test.csv\",encoding='latin-1')\n","datos.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id keyword location                                               text\n","0   0     NaN      NaN                 Just happened a terrible car crash\n","1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n","2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n","3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n","4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"xdwAFhBwV_oz","colab_type":"code","colab":{}},"source":["def tokenizarTexto(x):\n","  d = enchant.Dict(\"en\")\n","  x=x.casefold()\n","  x=re.sub(r'http\\S*', '',x)\n","  x=re.sub(r'[^a-z\\s]', '',x)\n","  lemma=WordNetLemmatizer()\n","  x=lemma.lemmatize(x)\n","  tokens=nltk.word_tokenize(x)\n","  #tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n","  #tokens = tknzr.tokenize(x)\n","  l=stopwords.words('english')+list(punctuation)\n","  tokens = [word for word in tokens if ((word not in l) & (d.check(word)))]\n","  return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_Sa90AKSe_T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596574895905,"user_tz":180,"elapsed":910545,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"94df78ae-8777-4b75-dc9c-65f7293c969f"},"source":["import re\n","def docToVec (train,datos):\n","  l=[]\n","  datosTweets=datos.apply(lambda x:[tokenizarTexto(x['text']),x['id']],axis=1).tolist()\n","  trainTweets=train.apply(lambda x:[tokenizarTexto(x['text']),x['id']],axis=1).tolist()\n","  for vectores in datosTweets:\n","    l.append(TaggedDocument(words=vectores[0], tags=str(vectores[1])))\n","  for vectores in trainTweets:\n","    l.append(TaggedDocument(words=vectores[0], tags=str(vectores[1])))\n","  max_epochs = 300\n","  vec_size = 200\n","  model = Doc2Vec(vector_size=vec_size, epochs=max_epochs)  \n","  model.build_vocab(l)\n","  model.train(l,total_examples=model.corpus_count,epochs=max_epochs)\n","  model.save('do2vec.model')\n","  ldatos=[]\n","  ltrain=[]\n","  for vectores in datosTweets:\n","    ldatos.append(model.infer_vector(vectores[0]))\n","  dfdatos= pd.DataFrame(ldatos)\n","  for vectores in trainTweets:\n","    ltrain.append(model.infer_vector(vectores[0]))\n","  dftrain= pd.DataFrame(ltrain)\n","  return (dfdatos,dftrain)\n","\n","(dfdatos,dftrain) = docToVec(train,datos)\n","dfdatos.to_csv('dfdatos.csv',encoding='utf-8',index=False)\n","dftrain.to_csv('dftrain.csv',encoding='utf-8',index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iUKmQOBPSj7Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596574897640,"user_tz":180,"elapsed":912275,"user":{"displayName":"Niko Farfan","photoUrl":"","userId":"18312784935668397664"}},"outputId":"9a7d6e84-968e-488d-90b3-43cc43982a48"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["catboost_info\t       dftrain\t       sample_submission.csv  XGBoost.ipynb\n","CatBoost.ipynb\t       do2vec.model    test.csv\n","colsample_bylevel.png  kaggle.json     train.csv\n","dfdatos\t\t       resultados.csv  Untitled0.ipynb\n"],"name":"stdout"}]}]}